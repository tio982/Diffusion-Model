# -*- coding: utf-8 -*-
"""utils

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13CGxYz62SrQJZ7Uw3f9Mno71JHJSC64W
"""

import wandb
import os
from torchvision.transforms.functional import to_pil_image
import cv2
import numpy as np
import torch
import tensorflow as tf
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.applications.inception_v3 import preprocess_input
from scipy.linalg import sqrtm

# Define a function to save images as W&B artifacts
def save_images_as_artifact(images, name):
    artifact = wandb.Artifact(name=name, type='images')
    for idx, image_data in enumerate(images):
        # Check if image_data is a tuple (image, label) or just an image
        if isinstance(image_data, tuple):
            image, _ = image_data  # Unpack image and discard label
        else:
            image = image_data  # No label, just the image

        # Convert tensor to PIL image
        image_pil = to_pil_image(image)
        # Save the PIL image
        image_path = os.path.join(wandb.run.dir, f"{name}_{idx}.jpg")
        image_pil.save(image_path)
        artifact.add_file(image_path, f"{name}_{idx}.jpg")
    wandb.run.log_artifact(artifact)

def save_images_locally(generated_images, folder_path):
    # Create the directory if it doesn't exist
    os.makedirs(folder_path, exist_ok=True)

    # Iterate over the generated images
    for i, img in enumerate(generated_images):
        # Move tensor to CPU and detach it from the computation graph
        img_cpu = img.cpu().detach()

        # Convert tensor to NumPy array
        img_np = img_cpu.numpy()

        # Convert image from [-1, 1] range back to [0, 255] range
        img_np = ((img_np + 1) * 127.5).astype(np.uint8)

        # Check the image shape and reorder the dimensions if needed
        if img_np.shape == (3, 32, 32):
            # Reorder the dimensions from (3, 32, 32) to (32, 32, 3)
            img_np = np.transpose(img_np, (1, 2, 0))

        # Convert image from RGB to BGR
        img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)

        # Save the image
        cv2.imwrite(os.path.join(folder_path, f'image_{i}.png'), img_bgr)

def calculate_fid(original_images, generated_images):
    # Load InceptionV3 model pre-trained on ImageNet
    model = InceptionV3(include_top=True, weights='imagenet')

    # Preprocess images
    original_images = preprocess_input(original_images)
    generated_images = preprocess_input(generated_images)

    # Get feature representations for FID
    model_avg = InceptionV3(include_top=False, pooling='avg')
    original_features = model_avg.predict(original_images)
    generated_features = model_avg.predict(generated_images)

    # Calculate mean and covariance statistics for FID
    mu_original = np.mean(original_features, axis=0)
    mu_generated = np.mean(generated_features, axis=0)

    # Calculate covariance matrices for FID
    sigma_original = np.cov(original_features, rowvar=False)
    sigma_generated = np.cov(generated_features, rowvar=False)

    # Regularization to improve numerical stability
    epsilon = 1
    sigma_original += np.eye(sigma_original.shape[0]) * epsilon
    sigma_generated += np.eye(sigma_generated.shape[0]) * epsilon

    # Calculate FID score
    diff = mu_original - mu_generated
    cov_sqrt = sqrtm(sigma_original.dot(sigma_generated))

    # Handle potential complex results from the square root of the covariance product
    if np.iscomplexobj(cov_sqrt):
        cov_sqrt = cov_sqrt.real

    fid_score = np.sum(diff**2) + np.trace(sigma_original + sigma_generated - 2 * cov_sqrt)
    fid_score = fid_score * 100
    # Calculate Inception Score
    # Use the output of the model (predicted probabilities) for generated images
    predictions = model.predict(generated_images)
    
    # Compute the marginal distribution p(y)
    marginal_prob = np.mean(predictions, axis=0)
    
    # Compute KL divergence
    kl_divergence = predictions * np.log(predictions / marginal_prob)
    kl_divergence = np.sum(kl_divergence, axis=1)
    
    # Calculate IS
    inception_score = np.exp(np.mean(kl_divergence))
    
    return fid_score, inception_score

def read_and_preprocess_images(folder_path):
    images = []
    for filename in os.listdir(folder_path):
        # Read image
        image_path = os.path.join(folder_path, filename)
        img = cv2.imread(image_path)
        if img is None:
            continue

        # Convert BGR to RGB
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # Resize image to (299, 299)
        img_resized = cv2.resize(img_rgb, (299, 299))

        # Convert pixel values to float32
        img_float32 = img_resized.astype(np.float32)

        # Normalize pixel values to the range [-1, 1]
        img_normalized = (img_float32 / 127.5) - 1.0

        images.append(img_normalized)

    return np.array(images)

def examine_images(original_images, generated_images):
    # Examine original images
    print("Original Images:")
    print(f"Data type: {original_images.dtype}")
    print(f"Shape: {original_images.shape}")
    print(f"Range of pixel values: [{np.min(original_images)}, {np.max(original_images)}]")

    # Examine generated images
    print("\nGenerated Images:")
    print(f"Data type: {generated_images.dtype}")
    print(f"Shape: {generated_images.shape}")
    print(f"Range of pixel values: [{np.min(generated_images)}, {np.max(generated_images)}]")